{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexandermakeev/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'invalid': 'warn', 'over': 'warn', 'under': 'ignore'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "from datetime import datetime, timedelta, date\n",
    "import calendar\n",
    "from sys import getsizeof\n",
    "import math, collections, io, re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.sparse import *\n",
    "from scipy.spatial.distance import euclidean, seuclidean\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from scipy.sparse import lil_matrix, csc_matrix, csr_matrix, coo_matrix\n",
    "from scipy.sparse import hstack, vstack\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy.stats import skew\n",
    "\n",
    "import pickle\n",
    "import yaml\n",
    "import json\n",
    "import sys, getopt, fnmatch, gc\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import collections\n",
    "\n",
    "pd.options.display.max_rows = 200\n",
    "pd.options.display.max_columns = 200\n",
    "np.seterr(divide='ignore', invalid='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('./input/sample_submission_sLex1ul.csv')\n",
    "origin_train = pd.read_csv('./input/train_ZoGVYWq.csv')\n",
    "origin_test = pd.read_csv('./input/test_66516Ee.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "origin_train = pd.concat([origin_train, pd.get_dummies(origin_train.sourcing_channel)], axis=1, join_axes=[origin_train.index])\n",
    "origin_test = pd.concat([origin_test, pd.get_dummies(origin_test.sourcing_channel)], axis=1, join_axes=[origin_test.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "origin_train = pd.concat([origin_train, pd.get_dummies(origin_train.residence_area_type)], axis=1, join_axes=[origin_train.index])\n",
    "origin_test = pd.concat([origin_test, pd.get_dummies(origin_test.residence_area_type)], axis=1, join_axes=[origin_test.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "origin_train['total_count'] = origin_train['Count_3-6_months_late'] + origin_train['Count_6-12_months_late'] + origin_train['Count_more_than_12_months_late']\n",
    "origin_test['total_count'] = origin_test['Count_3-6_months_late'] + origin_test['Count_6-12_months_late'] + origin_test['Count_more_than_12_months_late']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "application_underwriting_score_mean = origin_train.application_underwriting_score.mean()\n",
    "\n",
    "origin_train.application_underwriting_score.fillna(application_underwriting_score_mean, inplace=True)\n",
    "origin_test.application_underwriting_score.fillna(application_underwriting_score_mean, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create matrixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_feature_names = [\n",
    "    'perc_premium_paid_by_cash_credit', 'age_in_days', 'Income',\n",
    "    'Count_3-6_months_late', 'Count_6-12_months_late', 'Count_more_than_12_months_late',\n",
    "    'application_underwriting_score', 'no_of_premiums_paid',\n",
    "    'A', 'B', 'C', 'D', 'E', 'Rural', 'Urban', 'total_count',\n",
    "    'premium'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_train_sparse = csr_matrix(origin_train[full_feature_names])\n",
    "full_test_sparse = csr_matrix(origin_test[full_feature_names])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_predict(data, y, test):\n",
    "    dtrain = lgb.Dataset(data=data, label=y, free_raw_data=False)\n",
    "    dtrain.construct()\n",
    "\n",
    "    oof_preds = np.zeros(data.shape[0])\n",
    "    sub_preds = np.zeros(test.shape[0])\n",
    "\n",
    "    lgb_params = {\n",
    "        \"objective\" : \"binary\",\n",
    "        \"metric\" : \"binary_logloss\",\n",
    "#         \"metric\" : \"auc\",\n",
    "\n",
    "#         'max_depth': 3,\n",
    "        \"num_leaves\": 10,\n",
    "        \"min_data_in_leaf\": 10,\n",
    "        \"learning_rate\": 0.01,\n",
    "\n",
    "        \"feature_fraction\": 0.3,\n",
    "        \"feature_fraction_seed\": 10,\n",
    "\n",
    "        \"bagging_fraction\": 0.8,\n",
    "        \"bagging_freq\" : 10,\n",
    "        \"bagging_seed\" : 42, #2018\n",
    "\n",
    "        \"verbosity\" : 1,\n",
    "#         'lambda_l1' : 10,\n",
    "#         'lambda_l2' : 10,\n",
    "        'max_bin' : 50\n",
    "    }\n",
    "\n",
    "    folds = KFold(n_splits=7, shuffle=True, random_state=2)\n",
    "\n",
    "    counter = 1\n",
    "    for trn_idx, val_idx in folds.split(data):\n",
    "        print('----------------------------')\n",
    "        print('Fold: %d' % counter)\n",
    "\n",
    "        trn_d = dtrain.subset(trn_idx)\n",
    "        val_d = dtrain.subset(val_idx)\n",
    "\n",
    "        clf = lgb.train(\n",
    "            params=lgb_params,\n",
    "            train_set=trn_d,\n",
    "            valid_sets=[trn_d, val_d],\n",
    "            num_boost_round=10000,\n",
    "            early_stopping_rounds=100,\n",
    "            verbose_eval=50\n",
    "        )\n",
    "\n",
    "        oof_preds[val_idx] = clf.predict(dtrain.data[val_idx, :])\n",
    "        sub_preds += clf.predict(test) / folds.n_splits\n",
    "        \n",
    "        counter += 1\n",
    "\n",
    "    print('Full Out-Of-Fold score : %9.6f' % (mean_squared_error(y, oof_preds)**0.5))\n",
    "\n",
    "    return oof_preds, sub_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "Fold: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\ttraining's binary_logloss: 0.4321\tvalid_1's binary_logloss: 0.430339\n",
      "[100]\ttraining's binary_logloss: 0.312031\tvalid_1's binary_logloss: 0.309161\n",
      "[150]\ttraining's binary_logloss: 0.251775\tvalid_1's binary_logloss: 0.248142\n",
      "[200]\ttraining's binary_logloss: 0.219619\tvalid_1's binary_logloss: 0.215519\n",
      "[250]\ttraining's binary_logloss: 0.202765\tvalid_1's binary_logloss: 0.19838\n",
      "[300]\ttraining's binary_logloss: 0.192905\tvalid_1's binary_logloss: 0.188443\n",
      "[350]\ttraining's binary_logloss: 0.187307\tvalid_1's binary_logloss: 0.182879\n",
      "[400]\ttraining's binary_logloss: 0.184005\tvalid_1's binary_logloss: 0.179667\n",
      "[450]\ttraining's binary_logloss: 0.181669\tvalid_1's binary_logloss: 0.17748\n",
      "[500]\ttraining's binary_logloss: 0.180279\tvalid_1's binary_logloss: 0.176312\n",
      "[550]\ttraining's binary_logloss: 0.179179\tvalid_1's binary_logloss: 0.175434\n",
      "[600]\ttraining's binary_logloss: 0.178414\tvalid_1's binary_logloss: 0.174846\n",
      "[650]\ttraining's binary_logloss: 0.177708\tvalid_1's binary_logloss: 0.17439\n",
      "[700]\ttraining's binary_logloss: 0.177138\tvalid_1's binary_logloss: 0.174013\n",
      "[750]\ttraining's binary_logloss: 0.176679\tvalid_1's binary_logloss: 0.173765\n",
      "[800]\ttraining's binary_logloss: 0.176195\tvalid_1's binary_logloss: 0.173548\n",
      "[850]\ttraining's binary_logloss: 0.175816\tvalid_1's binary_logloss: 0.173374\n",
      "[900]\ttraining's binary_logloss: 0.17545\tvalid_1's binary_logloss: 0.173244\n",
      "[950]\ttraining's binary_logloss: 0.175095\tvalid_1's binary_logloss: 0.173115\n",
      "[1000]\ttraining's binary_logloss: 0.174746\tvalid_1's binary_logloss: 0.173011\n",
      "[1050]\ttraining's binary_logloss: 0.174443\tvalid_1's binary_logloss: 0.1729\n",
      "[1100]\ttraining's binary_logloss: 0.174129\tvalid_1's binary_logloss: 0.172873\n",
      "[1150]\ttraining's binary_logloss: 0.173817\tvalid_1's binary_logloss: 0.172792\n",
      "[1200]\ttraining's binary_logloss: 0.173537\tvalid_1's binary_logloss: 0.172763\n",
      "[1250]\ttraining's binary_logloss: 0.173247\tvalid_1's binary_logloss: 0.172734\n",
      "[1300]\ttraining's binary_logloss: 0.172989\tvalid_1's binary_logloss: 0.172695\n",
      "[1350]\ttraining's binary_logloss: 0.172735\tvalid_1's binary_logloss: 0.172655\n",
      "[1400]\ttraining's binary_logloss: 0.172485\tvalid_1's binary_logloss: 0.172625\n",
      "[1450]\ttraining's binary_logloss: 0.172246\tvalid_1's binary_logloss: 0.172622\n",
      "[1500]\ttraining's binary_logloss: 0.172003\tvalid_1's binary_logloss: 0.172566\n",
      "[1550]\ttraining's binary_logloss: 0.17175\tvalid_1's binary_logloss: 0.172559\n",
      "[1600]\ttraining's binary_logloss: 0.171516\tvalid_1's binary_logloss: 0.172568\n",
      "[1650]\ttraining's binary_logloss: 0.171244\tvalid_1's binary_logloss: 0.172519\n",
      "[1700]\ttraining's binary_logloss: 0.170994\tvalid_1's binary_logloss: 0.172517\n",
      "[1750]\ttraining's binary_logloss: 0.170774\tvalid_1's binary_logloss: 0.172494\n",
      "[1800]\ttraining's binary_logloss: 0.170533\tvalid_1's binary_logloss: 0.172478\n",
      "[1850]\ttraining's binary_logloss: 0.170293\tvalid_1's binary_logloss: 0.172459\n",
      "[1900]\ttraining's binary_logloss: 0.170053\tvalid_1's binary_logloss: 0.172432\n",
      "[1950]\ttraining's binary_logloss: 0.169851\tvalid_1's binary_logloss: 0.172433\n",
      "Early stopping, best iteration is:\n",
      "[1897]\ttraining's binary_logloss: 0.170067\tvalid_1's binary_logloss: 0.172428\n",
      "----------------------------\n",
      "Fold: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\ttraining's binary_logloss: 0.432122\tvalid_1's binary_logloss: 0.430014\n",
      "[100]\ttraining's binary_logloss: 0.312022\tvalid_1's binary_logloss: 0.308717\n",
      "[150]\ttraining's binary_logloss: 0.251674\tvalid_1's binary_logloss: 0.247857\n",
      "[200]\ttraining's binary_logloss: 0.219582\tvalid_1's binary_logloss: 0.215506\n",
      "[250]\ttraining's binary_logloss: 0.202676\tvalid_1's binary_logloss: 0.198713\n",
      "[300]\ttraining's binary_logloss: 0.192789\tvalid_1's binary_logloss: 0.189173\n",
      "[350]\ttraining's binary_logloss: 0.187056\tvalid_1's binary_logloss: 0.183828\n",
      "[400]\ttraining's binary_logloss: 0.183617\tvalid_1's binary_logloss: 0.180895\n",
      "[450]\ttraining's binary_logloss: 0.181207\tvalid_1's binary_logloss: 0.179035\n",
      "[500]\ttraining's binary_logloss: 0.179801\tvalid_1's binary_logloss: 0.178105\n",
      "[550]\ttraining's binary_logloss: 0.178655\tvalid_1's binary_logloss: 0.17745\n",
      "[600]\ttraining's binary_logloss: 0.177847\tvalid_1's binary_logloss: 0.177127\n",
      "[650]\ttraining's binary_logloss: 0.177122\tvalid_1's binary_logloss: 0.176854\n",
      "[700]\ttraining's binary_logloss: 0.176482\tvalid_1's binary_logloss: 0.176689\n",
      "[750]\ttraining's binary_logloss: 0.176022\tvalid_1's binary_logloss: 0.176664\n",
      "[800]\ttraining's binary_logloss: 0.175543\tvalid_1's binary_logloss: 0.176594\n",
      "[850]\ttraining's binary_logloss: 0.175138\tvalid_1's binary_logloss: 0.176581\n",
      "[900]\ttraining's binary_logloss: 0.174752\tvalid_1's binary_logloss: 0.176576\n",
      "[950]\ttraining's binary_logloss: 0.174399\tvalid_1's binary_logloss: 0.176564\n",
      "[1000]\ttraining's binary_logloss: 0.174047\tvalid_1's binary_logloss: 0.1766\n",
      "[1050]\ttraining's binary_logloss: 0.173714\tvalid_1's binary_logloss: 0.176576\n",
      "Early stopping, best iteration is:\n",
      "[955]\ttraining's binary_logloss: 0.174364\tvalid_1's binary_logloss: 0.176557\n",
      "----------------------------\n",
      "Fold: 3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\ttraining's binary_logloss: 0.431304\tvalid_1's binary_logloss: 0.433156\n",
      "[100]\ttraining's binary_logloss: 0.310856\tvalid_1's binary_logloss: 0.314038\n",
      "[150]\ttraining's binary_logloss: 0.250446\tvalid_1's binary_logloss: 0.254522\n",
      "[200]\ttraining's binary_logloss: 0.218299\tvalid_1's binary_logloss: 0.22308\n",
      "[250]\ttraining's binary_logloss: 0.201375\tvalid_1's binary_logloss: 0.20665\n",
      "[300]\ttraining's binary_logloss: 0.19155\tvalid_1's binary_logloss: 0.197185\n",
      "[350]\ttraining's binary_logloss: 0.185919\tvalid_1's binary_logloss: 0.191783\n",
      "[400]\ttraining's binary_logloss: 0.182583\tvalid_1's binary_logloss: 0.188638\n",
      "[450]\ttraining's binary_logloss: 0.180211\tvalid_1's binary_logloss: 0.186354\n",
      "[500]\ttraining's binary_logloss: 0.178831\tvalid_1's binary_logloss: 0.185193\n",
      "[550]\ttraining's binary_logloss: 0.177735\tvalid_1's binary_logloss: 0.184301\n",
      "[600]\ttraining's binary_logloss: 0.176958\tvalid_1's binary_logloss: 0.183722\n",
      "[650]\ttraining's binary_logloss: 0.176265\tvalid_1's binary_logloss: 0.183192\n",
      "[700]\ttraining's binary_logloss: 0.175649\tvalid_1's binary_logloss: 0.182787\n",
      "[750]\ttraining's binary_logloss: 0.175198\tvalid_1's binary_logloss: 0.182538\n",
      "[800]\ttraining's binary_logloss: 0.174732\tvalid_1's binary_logloss: 0.1823\n",
      "[850]\ttraining's binary_logloss: 0.174342\tvalid_1's binary_logloss: 0.182143\n",
      "[900]\ttraining's binary_logloss: 0.173985\tvalid_1's binary_logloss: 0.182012\n",
      "[950]\ttraining's binary_logloss: 0.173647\tvalid_1's binary_logloss: 0.181926\n",
      "[1000]\ttraining's binary_logloss: 0.173313\tvalid_1's binary_logloss: 0.181818\n",
      "[1050]\ttraining's binary_logloss: 0.173001\tvalid_1's binary_logloss: 0.181736\n",
      "[1100]\ttraining's binary_logloss: 0.17269\tvalid_1's binary_logloss: 0.181674\n",
      "[1150]\ttraining's binary_logloss: 0.17238\tvalid_1's binary_logloss: 0.18159\n",
      "[1200]\ttraining's binary_logloss: 0.172098\tvalid_1's binary_logloss: 0.181529\n",
      "[1250]\ttraining's binary_logloss: 0.171828\tvalid_1's binary_logloss: 0.181484\n",
      "[1300]\ttraining's binary_logloss: 0.17157\tvalid_1's binary_logloss: 0.181463\n",
      "[1350]\ttraining's binary_logloss: 0.171311\tvalid_1's binary_logloss: 0.18141\n",
      "[1400]\ttraining's binary_logloss: 0.171046\tvalid_1's binary_logloss: 0.181399\n",
      "[1450]\ttraining's binary_logloss: 0.170784\tvalid_1's binary_logloss: 0.181364\n",
      "[1500]\ttraining's binary_logloss: 0.170553\tvalid_1's binary_logloss: 0.181333\n",
      "[1550]\ttraining's binary_logloss: 0.170306\tvalid_1's binary_logloss: 0.181289\n",
      "[1600]\ttraining's binary_logloss: 0.170072\tvalid_1's binary_logloss: 0.181271\n",
      "[1650]\ttraining's binary_logloss: 0.169821\tvalid_1's binary_logloss: 0.181273\n",
      "[1700]\ttraining's binary_logloss: 0.16959\tvalid_1's binary_logloss: 0.181214\n",
      "[1750]\ttraining's binary_logloss: 0.169378\tvalid_1's binary_logloss: 0.181222\n",
      "[1800]\ttraining's binary_logloss: 0.169174\tvalid_1's binary_logloss: 0.181211\n",
      "[1850]\ttraining's binary_logloss: 0.168958\tvalid_1's binary_logloss: 0.181207\n",
      "[1900]\ttraining's binary_logloss: 0.168701\tvalid_1's binary_logloss: 0.181167\n",
      "[1950]\ttraining's binary_logloss: 0.168514\tvalid_1's binary_logloss: 0.181156\n",
      "[2000]\ttraining's binary_logloss: 0.168303\tvalid_1's binary_logloss: 0.181191\n",
      "Early stopping, best iteration is:\n",
      "[1921]\ttraining's binary_logloss: 0.168621\tvalid_1's binary_logloss: 0.181147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "Fold: 4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\ttraining's binary_logloss: 0.432014\tvalid_1's binary_logloss: 0.430743\n",
      "[100]\ttraining's binary_logloss: 0.311925\tvalid_1's binary_logloss: 0.309838\n",
      "[150]\ttraining's binary_logloss: 0.251748\tvalid_1's binary_logloss: 0.248872\n",
      "[200]\ttraining's binary_logloss: 0.21971\tvalid_1's binary_logloss: 0.216266\n",
      "[250]\ttraining's binary_logloss: 0.202864\tvalid_1's binary_logloss: 0.19896\n",
      "[300]\ttraining's binary_logloss: 0.193082\tvalid_1's binary_logloss: 0.188829\n",
      "[350]\ttraining's binary_logloss: 0.1875\tvalid_1's binary_logloss: 0.183104\n",
      "[400]\ttraining's binary_logloss: 0.18418\tvalid_1's binary_logloss: 0.179735\n",
      "[450]\ttraining's binary_logloss: 0.18184\tvalid_1's binary_logloss: 0.177424\n",
      "[500]\ttraining's binary_logloss: 0.180456\tvalid_1's binary_logloss: 0.176185\n",
      "[550]\ttraining's binary_logloss: 0.17932\tvalid_1's binary_logloss: 0.175206\n",
      "[600]\ttraining's binary_logloss: 0.178545\tvalid_1's binary_logloss: 0.174594\n",
      "[650]\ttraining's binary_logloss: 0.177843\tvalid_1's binary_logloss: 0.174105\n",
      "[700]\ttraining's binary_logloss: 0.17724\tvalid_1's binary_logloss: 0.173711\n",
      "[750]\ttraining's binary_logloss: 0.176768\tvalid_1's binary_logloss: 0.173507\n",
      "[800]\ttraining's binary_logloss: 0.176304\tvalid_1's binary_logloss: 0.17326\n",
      "[850]\ttraining's binary_logloss: 0.175915\tvalid_1's binary_logloss: 0.17314\n",
      "[900]\ttraining's binary_logloss: 0.175551\tvalid_1's binary_logloss: 0.173011\n",
      "[950]\ttraining's binary_logloss: 0.175221\tvalid_1's binary_logloss: 0.172945\n",
      "[1000]\ttraining's binary_logloss: 0.174904\tvalid_1's binary_logloss: 0.172883\n",
      "[1050]\ttraining's binary_logloss: 0.174587\tvalid_1's binary_logloss: 0.172773\n",
      "[1100]\ttraining's binary_logloss: 0.174265\tvalid_1's binary_logloss: 0.172701\n",
      "[1150]\ttraining's binary_logloss: 0.173952\tvalid_1's binary_logloss: 0.172644\n",
      "[1200]\ttraining's binary_logloss: 0.173611\tvalid_1's binary_logloss: 0.172685\n",
      "Early stopping, best iteration is:\n",
      "[1149]\ttraining's binary_logloss: 0.17396\tvalid_1's binary_logloss: 0.172644\n",
      "----------------------------\n",
      "Fold: 5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\ttraining's binary_logloss: 0.431456\tvalid_1's binary_logloss: 0.432518\n",
      "[100]\ttraining's binary_logloss: 0.311202\tvalid_1's binary_logloss: 0.312721\n",
      "[150]\ttraining's binary_logloss: 0.250879\tvalid_1's binary_logloss: 0.252702\n",
      "[200]\ttraining's binary_logloss: 0.218751\tvalid_1's binary_logloss: 0.220656\n",
      "[250]\ttraining's binary_logloss: 0.201962\tvalid_1's binary_logloss: 0.204012\n",
      "[300]\ttraining's binary_logloss: 0.192134\tvalid_1's binary_logloss: 0.194118\n",
      "[350]\ttraining's binary_logloss: 0.186491\tvalid_1's binary_logloss: 0.188422\n",
      "[400]\ttraining's binary_logloss: 0.18315\tvalid_1's binary_logloss: 0.185105\n",
      "[450]\ttraining's binary_logloss: 0.180812\tvalid_1's binary_logloss: 0.182781\n",
      "[500]\ttraining's binary_logloss: 0.179448\tvalid_1's binary_logloss: 0.181548\n",
      "[550]\ttraining's binary_logloss: 0.178355\tvalid_1's binary_logloss: 0.18063\n",
      "[600]\ttraining's binary_logloss: 0.177595\tvalid_1's binary_logloss: 0.180066\n",
      "[650]\ttraining's binary_logloss: 0.176905\tvalid_1's binary_logloss: 0.179564\n",
      "[700]\ttraining's binary_logloss: 0.176318\tvalid_1's binary_logloss: 0.179168\n",
      "[750]\ttraining's binary_logloss: 0.175862\tvalid_1's binary_logloss: 0.178954\n",
      "[800]\ttraining's binary_logloss: 0.175404\tvalid_1's binary_logloss: 0.178755\n",
      "[850]\ttraining's binary_logloss: 0.175002\tvalid_1's binary_logloss: 0.178601\n",
      "[900]\ttraining's binary_logloss: 0.174632\tvalid_1's binary_logloss: 0.178439\n",
      "[950]\ttraining's binary_logloss: 0.174293\tvalid_1's binary_logloss: 0.178352\n",
      "[1000]\ttraining's binary_logloss: 0.173959\tvalid_1's binary_logloss: 0.178234\n",
      "[1050]\ttraining's binary_logloss: 0.173647\tvalid_1's binary_logloss: 0.178112\n",
      "[1100]\ttraining's binary_logloss: 0.173332\tvalid_1's binary_logloss: 0.178073\n",
      "[1150]\ttraining's binary_logloss: 0.17303\tvalid_1's binary_logloss: 0.177987\n",
      "[1200]\ttraining's binary_logloss: 0.172735\tvalid_1's binary_logloss: 0.177977\n",
      "[1250]\ttraining's binary_logloss: 0.172448\tvalid_1's binary_logloss: 0.177938\n",
      "[1300]\ttraining's binary_logloss: 0.172178\tvalid_1's binary_logloss: 0.177907\n",
      "[1350]\ttraining's binary_logloss: 0.171916\tvalid_1's binary_logloss: 0.177878\n",
      "[1400]\ttraining's binary_logloss: 0.171634\tvalid_1's binary_logloss: 0.17792\n",
      "Early stopping, best iteration is:\n",
      "[1341]\ttraining's binary_logloss: 0.171961\tvalid_1's binary_logloss: 0.177877\n",
      "----------------------------\n",
      "Fold: 6\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\ttraining's binary_logloss: 0.43124\tvalid_1's binary_logloss: 0.433298\n",
      "[100]\ttraining's binary_logloss: 0.31063\tvalid_1's binary_logloss: 0.314392\n",
      "[150]\ttraining's binary_logloss: 0.250053\tvalid_1's binary_logloss: 0.255278\n",
      "[200]\ttraining's binary_logloss: 0.217816\tvalid_1's binary_logloss: 0.224385\n",
      "[250]\ttraining's binary_logloss: 0.200788\tvalid_1's binary_logloss: 0.208487\n",
      "[300]\ttraining's binary_logloss: 0.19089\tvalid_1's binary_logloss: 0.199635\n",
      "[350]\ttraining's binary_logloss: 0.18513\tvalid_1's binary_logloss: 0.194764\n",
      "[400]\ttraining's binary_logloss: 0.181723\tvalid_1's binary_logloss: 0.192061\n",
      "[450]\ttraining's binary_logloss: 0.179316\tvalid_1's binary_logloss: 0.1904\n",
      "[500]\ttraining's binary_logloss: 0.177906\tvalid_1's binary_logloss: 0.189525\n",
      "[550]\ttraining's binary_logloss: 0.176816\tvalid_1's binary_logloss: 0.188835\n",
      "[600]\ttraining's binary_logloss: 0.176031\tvalid_1's binary_logloss: 0.188487\n",
      "[650]\ttraining's binary_logloss: 0.17531\tvalid_1's binary_logloss: 0.188148\n",
      "[700]\ttraining's binary_logloss: 0.174708\tvalid_1's binary_logloss: 0.187924\n",
      "[750]\ttraining's binary_logloss: 0.174251\tvalid_1's binary_logloss: 0.187741\n",
      "[800]\ttraining's binary_logloss: 0.173767\tvalid_1's binary_logloss: 0.187549\n",
      "[850]\ttraining's binary_logloss: 0.173364\tvalid_1's binary_logloss: 0.187439\n",
      "[900]\ttraining's binary_logloss: 0.173001\tvalid_1's binary_logloss: 0.18739\n",
      "[950]\ttraining's binary_logloss: 0.172667\tvalid_1's binary_logloss: 0.187389\n",
      "[1000]\ttraining's binary_logloss: 0.172327\tvalid_1's binary_logloss: 0.187335\n",
      "[1050]\ttraining's binary_logloss: 0.172004\tvalid_1's binary_logloss: 0.187338\n",
      "[1100]\ttraining's binary_logloss: 0.171676\tvalid_1's binary_logloss: 0.187256\n",
      "[1150]\ttraining's binary_logloss: 0.171363\tvalid_1's binary_logloss: 0.187243\n",
      "[1200]\ttraining's binary_logloss: 0.171056\tvalid_1's binary_logloss: 0.187239\n",
      "Early stopping, best iteration is:\n",
      "[1129]\ttraining's binary_logloss: 0.171489\tvalid_1's binary_logloss: 0.187219\n",
      "----------------------------\n",
      "Fold: 7\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\ttraining's binary_logloss: 0.431248\tvalid_1's binary_logloss: 0.432626\n",
      "[100]\ttraining's binary_logloss: 0.310898\tvalid_1's binary_logloss: 0.313165\n",
      "[150]\ttraining's binary_logloss: 0.250484\tvalid_1's binary_logloss: 0.25346\n",
      "[200]\ttraining's binary_logloss: 0.218359\tvalid_1's binary_logloss: 0.221921\n",
      "[250]\ttraining's binary_logloss: 0.201446\tvalid_1's binary_logloss: 0.205578\n",
      "[300]\ttraining's binary_logloss: 0.191556\tvalid_1's binary_logloss: 0.196142\n",
      "[350]\ttraining's binary_logloss: 0.185914\tvalid_1's binary_logloss: 0.19092\n",
      "[400]\ttraining's binary_logloss: 0.182516\tvalid_1's binary_logloss: 0.187895\n",
      "[450]\ttraining's binary_logloss: 0.180141\tvalid_1's binary_logloss: 0.185927\n",
      "[500]\ttraining's binary_logloss: 0.178742\tvalid_1's binary_logloss: 0.184851\n",
      "[550]\ttraining's binary_logloss: 0.177621\tvalid_1's binary_logloss: 0.184068\n",
      "[600]\ttraining's binary_logloss: 0.176824\tvalid_1's binary_logloss: 0.183644\n",
      "[650]\ttraining's binary_logloss: 0.176124\tvalid_1's binary_logloss: 0.183258\n",
      "[700]\ttraining's binary_logloss: 0.175531\tvalid_1's binary_logloss: 0.182962\n",
      "[750]\ttraining's binary_logloss: 0.175057\tvalid_1's binary_logloss: 0.182815\n",
      "[800]\ttraining's binary_logloss: 0.174573\tvalid_1's binary_logloss: 0.182686\n",
      "[850]\ttraining's binary_logloss: 0.174194\tvalid_1's binary_logloss: 0.182601\n",
      "[900]\ttraining's binary_logloss: 0.173824\tvalid_1's binary_logloss: 0.182518\n",
      "[950]\ttraining's binary_logloss: 0.173484\tvalid_1's binary_logloss: 0.18248\n",
      "[1000]\ttraining's binary_logloss: 0.173127\tvalid_1's binary_logloss: 0.182449\n",
      "[1050]\ttraining's binary_logloss: 0.172794\tvalid_1's binary_logloss: 0.182409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1100]\ttraining's binary_logloss: 0.172488\tvalid_1's binary_logloss: 0.18236\n",
      "[1150]\ttraining's binary_logloss: 0.172165\tvalid_1's binary_logloss: 0.182322\n",
      "[1200]\ttraining's binary_logloss: 0.171868\tvalid_1's binary_logloss: 0.182328\n",
      "[1250]\ttraining's binary_logloss: 0.171604\tvalid_1's binary_logloss: 0.182339\n",
      "Early stopping, best iteration is:\n",
      "[1180]\ttraining's binary_logloss: 0.171977\tvalid_1's binary_logloss: 0.1823\n",
      "Full Out-Of-Fold score :  0.219779\n"
     ]
    }
   ],
   "source": [
    "train_renewal_preds, test_renewal_preds = fit_predict(full_train_sparse, origin_train.renewal, full_test_sparse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtest = xgb.DMatrix(full_test_sparse, feature_names=full_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_predict_xgboost(data, y, dtest):\n",
    "\n",
    "    oof_preds = np.zeros(data.shape[0])\n",
    "    sub_preds = np.zeros(dtest.num_row())\n",
    "\n",
    "    params = {\n",
    "        'booster': 'gbtree',\n",
    "        'objective': 'binary:logistic',\n",
    "        'max_depth': 3,\n",
    "        'eta': 0.01,\n",
    "        'eval_metric': 'logloss',\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bytree': 0.3,\n",
    "    #     'min_child_weight': 5,\n",
    "    #     'lambda': 10,\n",
    "    #     'alpha': 10,\n",
    "        'nthread': 4\n",
    "    #     'silent': 1,\n",
    "    }\n",
    "\n",
    "\n",
    "    folds = KFold(n_splits=7, shuffle=True, random_state=1)\n",
    "\n",
    "    counter = 1\n",
    "    for trn_idx, val_idx in folds.split(data):\n",
    "        print('----------------------------')\n",
    "        print('Fold: %d' % counter)\n",
    "\n",
    "        dtrain_sample = xgb.DMatrix(data[trn_idx], label=y[trn_idx], feature_names=full_feature_names)\n",
    "        dvalid_sample = xgb.DMatrix(data[val_idx], label=y[val_idx], feature_names=full_feature_names)\n",
    "        assert(dtrain_sample.num_col() == dvalid_sample.num_col())\n",
    "        assert(dtrain_sample.num_col() == len(full_feature_names))\n",
    "        assert(dtrain_sample.num_col() == data.shape[1])\n",
    "        assert(dvalid_sample.num_col() == data.shape[1])\n",
    "\n",
    "        watchlist  = [(dtrain_sample, 'train'), (dvalid_sample, 'valid')]\n",
    "        num_round = 10000\n",
    "        xgb_model = xgb.train(params, dtrain_sample, num_round, watchlist,\n",
    "                              verbose_eval=50,\n",
    "                              early_stopping_rounds=100)\n",
    "\n",
    "        oof_preds[val_idx] = xgb_model.predict(dvalid_sample)\n",
    "        sub_preds += xgb_model.predict(dtest) / folds.n_splits\n",
    "\n",
    "        counter += 1\n",
    "\n",
    "    print('Full Out-Of-Fold score : %9.6f'\n",
    "          % (mean_squared_error(y, oof_preds)**0.5))\n",
    "\n",
    "    return oof_preds, sub_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "Fold: 1\n",
      "[0]\ttrain-logloss:0.685219\tvalid-logloss:0.685253\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 100 rounds.\n",
      "[50]\ttrain-logloss:0.428939\tvalid-logloss:0.430028\n",
      "[100]\ttrain-logloss:0.31108\tvalid-logloss:0.312966\n",
      "[150]\ttrain-logloss:0.252593\tvalid-logloss:0.25521\n",
      "[200]\ttrain-logloss:0.219996\tvalid-logloss:0.223113\n",
      "[250]\ttrain-logloss:0.202617\tvalid-logloss:0.206247\n",
      "[300]\ttrain-logloss:0.19295\tvalid-logloss:0.196842\n",
      "[350]\ttrain-logloss:0.187761\tvalid-logloss:0.19199\n",
      "[400]\ttrain-logloss:0.184176\tvalid-logloss:0.188634\n",
      "[450]\ttrain-logloss:0.181984\tvalid-logloss:0.186545\n",
      "[500]\ttrain-logloss:0.180511\tvalid-logloss:0.185189\n",
      "[550]\ttrain-logloss:0.179455\tvalid-logloss:0.184238\n",
      "[600]\ttrain-logloss:0.178712\tvalid-logloss:0.183604\n",
      "[650]\ttrain-logloss:0.178191\tvalid-logloss:0.183265\n",
      "[700]\ttrain-logloss:0.177731\tvalid-logloss:0.18294\n",
      "[750]\ttrain-logloss:0.177316\tvalid-logloss:0.182653\n",
      "[800]\ttrain-logloss:0.176979\tvalid-logloss:0.182424\n",
      "[850]\ttrain-logloss:0.176697\tvalid-logloss:0.182296\n",
      "[900]\ttrain-logloss:0.176471\tvalid-logloss:0.18219\n",
      "[950]\ttrain-logloss:0.17625\tvalid-logloss:0.18213\n",
      "[1000]\ttrain-logloss:0.176041\tvalid-logloss:0.182064\n",
      "[1050]\ttrain-logloss:0.175846\tvalid-logloss:0.182001\n",
      "[1100]\ttrain-logloss:0.175661\tvalid-logloss:0.181956\n",
      "[1150]\ttrain-logloss:0.175509\tvalid-logloss:0.181924\n",
      "[1200]\ttrain-logloss:0.175379\tvalid-logloss:0.181902\n",
      "[1250]\ttrain-logloss:0.175227\tvalid-logloss:0.181895\n",
      "[1300]\ttrain-logloss:0.175086\tvalid-logloss:0.181876\n",
      "[1350]\ttrain-logloss:0.174971\tvalid-logloss:0.18186\n",
      "[1400]\ttrain-logloss:0.174866\tvalid-logloss:0.181869\n",
      "Stopping. Best iteration:\n",
      "[1335]\ttrain-logloss:0.175005\tvalid-logloss:0.181857\n",
      "\n",
      "----------------------------\n",
      "Fold: 2\n",
      "[0]\ttrain-logloss:0.685217\tvalid-logloss:0.685257\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 100 rounds.\n",
      "[50]\ttrain-logloss:0.428756\tvalid-logloss:0.430635\n",
      "[100]\ttrain-logloss:0.31017\tvalid-logloss:0.313469\n",
      "[150]\ttrain-logloss:0.251749\tvalid-logloss:0.256242\n",
      "[200]\ttrain-logloss:0.219959\tvalid-logloss:0.225423\n",
      "[250]\ttrain-logloss:0.202444\tvalid-logloss:0.208606\n",
      "[300]\ttrain-logloss:0.192794\tvalid-logloss:0.199524\n",
      "[350]\ttrain-logloss:0.187602\tvalid-logloss:0.194741\n",
      "[400]\ttrain-logloss:0.184004\tvalid-logloss:0.191343\n",
      "[450]\ttrain-logloss:0.18173\tvalid-logloss:0.189282\n",
      "[500]\ttrain-logloss:0.180189\tvalid-logloss:0.187896\n",
      "[550]\ttrain-logloss:0.179087\tvalid-logloss:0.186917\n",
      "[600]\ttrain-logloss:0.178343\tvalid-logloss:0.186233\n",
      "[650]\ttrain-logloss:0.177832\tvalid-logloss:0.185752\n",
      "[700]\ttrain-logloss:0.177394\tvalid-logloss:0.185431\n",
      "[750]\ttrain-logloss:0.177\tvalid-logloss:0.185111\n",
      "[800]\ttrain-logloss:0.176677\tvalid-logloss:0.184852\n",
      "[850]\ttrain-logloss:0.176411\tvalid-logloss:0.184657\n",
      "[900]\ttrain-logloss:0.176171\tvalid-logloss:0.184506\n",
      "[950]\ttrain-logloss:0.175966\tvalid-logloss:0.184357\n",
      "[1000]\ttrain-logloss:0.175797\tvalid-logloss:0.184223\n",
      "[1050]\ttrain-logloss:0.175634\tvalid-logloss:0.184099\n",
      "[1100]\ttrain-logloss:0.175507\tvalid-logloss:0.184024\n",
      "[1150]\ttrain-logloss:0.175389\tvalid-logloss:0.183973\n",
      "[1200]\ttrain-logloss:0.175276\tvalid-logloss:0.183935\n",
      "[1250]\ttrain-logloss:0.175158\tvalid-logloss:0.18387\n",
      "[1300]\ttrain-logloss:0.175056\tvalid-logloss:0.183827\n",
      "[1350]\ttrain-logloss:0.174956\tvalid-logloss:0.183787\n",
      "[1400]\ttrain-logloss:0.174874\tvalid-logloss:0.183753\n",
      "[1450]\ttrain-logloss:0.17477\tvalid-logloss:0.18372\n",
      "[1500]\ttrain-logloss:0.174669\tvalid-logloss:0.183709\n",
      "[1550]\ttrain-logloss:0.174574\tvalid-logloss:0.183678\n",
      "[1600]\ttrain-logloss:0.174498\tvalid-logloss:0.183655\n",
      "[1650]\ttrain-logloss:0.174442\tvalid-logloss:0.183652\n",
      "[1700]\ttrain-logloss:0.174387\tvalid-logloss:0.183646\n",
      "[1750]\ttrain-logloss:0.174323\tvalid-logloss:0.183631\n",
      "[1800]\ttrain-logloss:0.174247\tvalid-logloss:0.183626\n",
      "[1850]\ttrain-logloss:0.174178\tvalid-logloss:0.183609\n",
      "[1900]\ttrain-logloss:0.174112\tvalid-logloss:0.183588\n",
      "[1950]\ttrain-logloss:0.174043\tvalid-logloss:0.183565\n",
      "[2000]\ttrain-logloss:0.17397\tvalid-logloss:0.183561\n",
      "[2050]\ttrain-logloss:0.173896\tvalid-logloss:0.183553\n",
      "[2100]\ttrain-logloss:0.173841\tvalid-logloss:0.18354\n",
      "[2150]\ttrain-logloss:0.173783\tvalid-logloss:0.183531\n",
      "[2200]\ttrain-logloss:0.173729\tvalid-logloss:0.183533\n",
      "[2250]\ttrain-logloss:0.17368\tvalid-logloss:0.183528\n",
      "[2300]\ttrain-logloss:0.173623\tvalid-logloss:0.183517\n",
      "[2350]\ttrain-logloss:0.173564\tvalid-logloss:0.183501\n",
      "[2400]\ttrain-logloss:0.173522\tvalid-logloss:0.183503\n",
      "[2450]\ttrain-logloss:0.173454\tvalid-logloss:0.183507\n",
      "[2500]\ttrain-logloss:0.173408\tvalid-logloss:0.183501\n",
      "Stopping. Best iteration:\n",
      "[2434]\ttrain-logloss:0.173484\tvalid-logloss:0.183494\n",
      "\n",
      "----------------------------\n",
      "Fold: 3\n",
      "[0]\ttrain-logloss:0.685217\tvalid-logloss:0.685301\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 100 rounds.\n",
      "[50]\ttrain-logloss:0.427911\tvalid-logloss:0.430873\n",
      "[100]\ttrain-logloss:0.309091\tvalid-logloss:0.314111\n",
      "[150]\ttrain-logloss:0.250528\tvalid-logloss:0.257136\n",
      "[200]\ttrain-logloss:0.218495\tvalid-logloss:0.226307\n",
      "[250]\ttrain-logloss:0.201251\tvalid-logloss:0.210041\n",
      "[300]\ttrain-logloss:0.191612\tvalid-logloss:0.201174\n",
      "[350]\ttrain-logloss:0.186566\tvalid-logloss:0.196745\n",
      "[400]\ttrain-logloss:0.183075\tvalid-logloss:0.193727\n",
      "[450]\ttrain-logloss:0.180831\tvalid-logloss:0.191859\n",
      "[500]\ttrain-logloss:0.179408\tvalid-logloss:0.190693\n",
      "[550]\ttrain-logloss:0.178368\tvalid-logloss:0.189847\n",
      "[600]\ttrain-logloss:0.177628\tvalid-logloss:0.189305\n",
      "[650]\ttrain-logloss:0.177118\tvalid-logloss:0.188947\n",
      "[700]\ttrain-logloss:0.176681\tvalid-logloss:0.188634\n",
      "[750]\ttrain-logloss:0.176248\tvalid-logloss:0.188313\n",
      "[800]\ttrain-logloss:0.175909\tvalid-logloss:0.188109\n",
      "[850]\ttrain-logloss:0.175633\tvalid-logloss:0.187988\n",
      "[900]\ttrain-logloss:0.175424\tvalid-logloss:0.187847\n",
      "[950]\ttrain-logloss:0.175205\tvalid-logloss:0.187751\n",
      "[1000]\ttrain-logloss:0.174997\tvalid-logloss:0.187686\n",
      "[1050]\ttrain-logloss:0.17483\tvalid-logloss:0.18767\n",
      "[1100]\ttrain-logloss:0.174676\tvalid-logloss:0.187622\n",
      "[1150]\ttrain-logloss:0.174544\tvalid-logloss:0.187618\n",
      "[1200]\ttrain-logloss:0.174431\tvalid-logloss:0.187598\n",
      "[1250]\ttrain-logloss:0.174315\tvalid-logloss:0.187546\n",
      "[1300]\ttrain-logloss:0.174191\tvalid-logloss:0.187518\n",
      "[1350]\ttrain-logloss:0.174099\tvalid-logloss:0.187504\n",
      "[1400]\ttrain-logloss:0.174016\tvalid-logloss:0.187489\n",
      "[1450]\ttrain-logloss:0.17391\tvalid-logloss:0.187429\n",
      "[1500]\ttrain-logloss:0.173808\tvalid-logloss:0.187424\n",
      "[1550]\ttrain-logloss:0.173703\tvalid-logloss:0.187406\n",
      "[1600]\ttrain-logloss:0.173616\tvalid-logloss:0.187397\n",
      "[1650]\ttrain-logloss:0.173547\tvalid-logloss:0.187389\n",
      "[1700]\ttrain-logloss:0.173488\tvalid-logloss:0.187383\n",
      "[1750]\ttrain-logloss:0.173416\tvalid-logloss:0.187353\n",
      "[1800]\ttrain-logloss:0.173353\tvalid-logloss:0.187346\n",
      "[1850]\ttrain-logloss:0.17329\tvalid-logloss:0.187352\n",
      "[1900]\ttrain-logloss:0.173243\tvalid-logloss:0.187356\n",
      "Stopping. Best iteration:\n",
      "[1804]\ttrain-logloss:0.173344\tvalid-logloss:0.187343\n",
      "\n",
      "----------------------------\n",
      "Fold: 4\n",
      "[0]\ttrain-logloss:0.685548\tvalid-logloss:0.685511\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 100 rounds.\n",
      "[50]\ttrain-logloss:0.432111\tvalid-logloss:0.430785\n",
      "[100]\ttrain-logloss:0.315287\tvalid-logloss:0.313038\n",
      "[150]\ttrain-logloss:0.257761\tvalid-logloss:0.2548\n",
      "[200]\ttrain-logloss:0.226995\tvalid-logloss:0.22353\n",
      "[250]\ttrain-logloss:0.210096\tvalid-logloss:0.206211\n",
      "[300]\ttrain-logloss:0.199463\tvalid-logloss:0.195388\n",
      "[350]\ttrain-logloss:0.194539\tvalid-logloss:0.190335\n",
      "[400]\ttrain-logloss:0.190288\tvalid-logloss:0.186182\n",
      "[450]\ttrain-logloss:0.187395\tvalid-logloss:0.183411\n",
      "[500]\ttrain-logloss:0.184976\tvalid-logloss:0.181213\n",
      "[550]\ttrain-logloss:0.182858\tvalid-logloss:0.179351\n",
      "[600]\ttrain-logloss:0.181415\tvalid-logloss:0.178147\n",
      "[650]\ttrain-logloss:0.180489\tvalid-logloss:0.177441\n",
      "[700]\ttrain-logloss:0.179785\tvalid-logloss:0.176916\n",
      "[750]\ttrain-logloss:0.179124\tvalid-logloss:0.176492\n",
      "[800]\ttrain-logloss:0.178627\tvalid-logloss:0.176179\n",
      "[850]\ttrain-logloss:0.178274\tvalid-logloss:0.175989\n",
      "[900]\ttrain-logloss:0.177959\tvalid-logloss:0.175847\n",
      "[950]\ttrain-logloss:0.177691\tvalid-logloss:0.175734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\ttrain-logloss:0.177439\tvalid-logloss:0.175628\n",
      "[1050]\ttrain-logloss:0.177212\tvalid-logloss:0.175537\n",
      "[1100]\ttrain-logloss:0.177003\tvalid-logloss:0.175498\n",
      "[1150]\ttrain-logloss:0.176852\tvalid-logloss:0.175447\n",
      "[1200]\ttrain-logloss:0.176729\tvalid-logloss:0.175438\n",
      "[1250]\ttrain-logloss:0.176567\tvalid-logloss:0.17543\n",
      "[1300]\ttrain-logloss:0.1764\tvalid-logloss:0.175414\n",
      "[1350]\ttrain-logloss:0.176302\tvalid-logloss:0.175383\n",
      "[1400]\ttrain-logloss:0.176201\tvalid-logloss:0.175397\n",
      "[1450]\ttrain-logloss:0.176076\tvalid-logloss:0.175379\n",
      "[1500]\ttrain-logloss:0.175989\tvalid-logloss:0.175357\n",
      "[1550]\ttrain-logloss:0.17588\tvalid-logloss:0.175344\n",
      "[1600]\ttrain-logloss:0.175771\tvalid-logloss:0.175327\n",
      "[1650]\ttrain-logloss:0.175713\tvalid-logloss:0.175335\n",
      "[1700]\ttrain-logloss:0.175624\tvalid-logloss:0.175341\n",
      "Stopping. Best iteration:\n",
      "[1601]\ttrain-logloss:0.175769\tvalid-logloss:0.175326\n",
      "\n",
      "----------------------------\n",
      "Fold: 5\n",
      "[0]\ttrain-logloss:0.685224\tvalid-logloss:0.685191\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 100 rounds.\n",
      "[50]\ttrain-logloss:0.429956\tvalid-logloss:0.429356\n",
      "[100]\ttrain-logloss:0.313478\tvalid-logloss:0.312484\n",
      "[150]\ttrain-logloss:0.255347\tvalid-logloss:0.25398\n",
      "[200]\ttrain-logloss:0.224944\tvalid-logloss:0.223345\n",
      "[250]\ttrain-logloss:0.207661\tvalid-logloss:0.205863\n",
      "[300]\ttrain-logloss:0.197704\tvalid-logloss:0.195876\n",
      "[350]\ttrain-logloss:0.19205\tvalid-logloss:0.190148\n",
      "[400]\ttrain-logloss:0.187998\tvalid-logloss:0.186087\n",
      "[450]\ttrain-logloss:0.185114\tvalid-logloss:0.183337\n",
      "[500]\ttrain-logloss:0.183172\tvalid-logloss:0.181491\n",
      "[550]\ttrain-logloss:0.181598\tvalid-logloss:0.179985\n",
      "[600]\ttrain-logloss:0.18048\tvalid-logloss:0.17901\n",
      "[650]\ttrain-logloss:0.179746\tvalid-logloss:0.178422\n",
      "[700]\ttrain-logloss:0.179142\tvalid-logloss:0.177954\n",
      "[750]\ttrain-logloss:0.178709\tvalid-logloss:0.177631\n",
      "[800]\ttrain-logloss:0.178306\tvalid-logloss:0.177362\n",
      "[850]\ttrain-logloss:0.177972\tvalid-logloss:0.177207\n",
      "[900]\ttrain-logloss:0.177679\tvalid-logloss:0.177049\n",
      "[950]\ttrain-logloss:0.177428\tvalid-logloss:0.176918\n",
      "[1000]\ttrain-logloss:0.177218\tvalid-logloss:0.176818\n",
      "[1050]\ttrain-logloss:0.177035\tvalid-logloss:0.176765\n",
      "[1100]\ttrain-logloss:0.176868\tvalid-logloss:0.176714\n",
      "[1150]\ttrain-logloss:0.176724\tvalid-logloss:0.17669\n",
      "[1200]\ttrain-logloss:0.176578\tvalid-logloss:0.176654\n",
      "[1250]\ttrain-logloss:0.176434\tvalid-logloss:0.176616\n",
      "[1300]\ttrain-logloss:0.176312\tvalid-logloss:0.17657\n",
      "[1350]\ttrain-logloss:0.1762\tvalid-logloss:0.176536\n",
      "[1400]\ttrain-logloss:0.17608\tvalid-logloss:0.176496\n",
      "[1450]\ttrain-logloss:0.175959\tvalid-logloss:0.176484\n",
      "[1500]\ttrain-logloss:0.175855\tvalid-logloss:0.176459\n",
      "[1550]\ttrain-logloss:0.175756\tvalid-logloss:0.176461\n",
      "[1600]\ttrain-logloss:0.175669\tvalid-logloss:0.176456\n",
      "Stopping. Best iteration:\n",
      "[1517]\ttrain-logloss:0.175827\tvalid-logloss:0.176449\n",
      "\n",
      "----------------------------\n",
      "Fold: 6\n",
      "[0]\ttrain-logloss:0.685245\tvalid-logloss:0.685164\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 100 rounds.\n",
      "[50]\ttrain-logloss:0.429968\tvalid-logloss:0.427198\n",
      "[100]\ttrain-logloss:0.311948\tvalid-logloss:0.30728\n",
      "[150]\ttrain-logloss:0.252854\tvalid-logloss:0.246698\n",
      "[200]\ttrain-logloss:0.221786\tvalid-logloss:0.214584\n",
      "[250]\ttrain-logloss:0.204665\tvalid-logloss:0.196693\n",
      "[300]\ttrain-logloss:0.195768\tvalid-logloss:0.187286\n",
      "[350]\ttrain-logloss:0.190531\tvalid-logloss:0.181737\n",
      "[400]\ttrain-logloss:0.18707\tvalid-logloss:0.178133\n",
      "[450]\ttrain-logloss:0.18467\tvalid-logloss:0.175745\n",
      "[500]\ttrain-logloss:0.183222\tvalid-logloss:0.174348\n",
      "[550]\ttrain-logloss:0.181912\tvalid-logloss:0.173128\n",
      "[600]\ttrain-logloss:0.18093\tvalid-logloss:0.172266\n",
      "[650]\ttrain-logloss:0.180231\tvalid-logloss:0.171696\n",
      "[700]\ttrain-logloss:0.179669\tvalid-logloss:0.171304\n",
      "[750]\ttrain-logloss:0.179258\tvalid-logloss:0.171044\n",
      "[800]\ttrain-logloss:0.178891\tvalid-logloss:0.170855\n",
      "[850]\ttrain-logloss:0.178562\tvalid-logloss:0.17072\n",
      "[900]\ttrain-logloss:0.178277\tvalid-logloss:0.170571\n",
      "[950]\ttrain-logloss:0.178019\tvalid-logloss:0.170473\n",
      "[1000]\ttrain-logloss:0.177801\tvalid-logloss:0.170386\n",
      "[1050]\ttrain-logloss:0.177622\tvalid-logloss:0.170354\n",
      "[1100]\ttrain-logloss:0.177449\tvalid-logloss:0.170296\n",
      "[1150]\ttrain-logloss:0.177254\tvalid-logloss:0.170286\n",
      "[1200]\ttrain-logloss:0.177084\tvalid-logloss:0.170256\n",
      "[1250]\ttrain-logloss:0.176922\tvalid-logloss:0.17024\n",
      "[1300]\ttrain-logloss:0.176769\tvalid-logloss:0.170186\n",
      "[1350]\ttrain-logloss:0.176636\tvalid-logloss:0.170166\n",
      "[1400]\ttrain-logloss:0.176483\tvalid-logloss:0.170171\n",
      "[1450]\ttrain-logloss:0.176344\tvalid-logloss:0.170181\n",
      "Stopping. Best iteration:\n",
      "[1367]\ttrain-logloss:0.176581\tvalid-logloss:0.170154\n",
      "\n",
      "----------------------------\n",
      "Fold: 7\n",
      "[0]\ttrain-logloss:0.685242\tvalid-logloss:0.685239\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 100 rounds.\n",
      "[50]\ttrain-logloss:0.430544\tvalid-logloss:0.430157\n",
      "[100]\ttrain-logloss:0.313466\tvalid-logloss:0.312744\n",
      "[150]\ttrain-logloss:0.254742\tvalid-logloss:0.253758\n",
      "[200]\ttrain-logloss:0.223625\tvalid-logloss:0.22257\n",
      "[250]\ttrain-logloss:0.205966\tvalid-logloss:0.204879\n",
      "[300]\ttrain-logloss:0.196308\tvalid-logloss:0.195274\n",
      "[350]\ttrain-logloss:0.190681\tvalid-logloss:0.189741\n",
      "[400]\ttrain-logloss:0.18717\tvalid-logloss:0.186355\n",
      "[450]\ttrain-logloss:0.184772\tvalid-logloss:0.184092\n",
      "[500]\ttrain-logloss:0.183339\tvalid-logloss:0.18279\n",
      "[550]\ttrain-logloss:0.182206\tvalid-logloss:0.18181\n",
      "[600]\ttrain-logloss:0.181193\tvalid-logloss:0.18099\n",
      "[650]\ttrain-logloss:0.180697\tvalid-logloss:0.180562\n",
      "[700]\ttrain-logloss:0.180209\tvalid-logloss:0.180185\n",
      "[750]\ttrain-logloss:0.179739\tvalid-logloss:0.179849\n",
      "[800]\ttrain-logloss:0.179308\tvalid-logloss:0.179544\n",
      "[850]\ttrain-logloss:0.178963\tvalid-logloss:0.179306\n",
      "[900]\ttrain-logloss:0.178702\tvalid-logloss:0.179127\n",
      "[950]\ttrain-logloss:0.178451\tvalid-logloss:0.178957\n",
      "[1000]\ttrain-logloss:0.178217\tvalid-logloss:0.178789\n",
      "[1050]\ttrain-logloss:0.177948\tvalid-logloss:0.178618\n",
      "[1100]\ttrain-logloss:0.177631\tvalid-logloss:0.178362\n",
      "[1150]\ttrain-logloss:0.177405\tvalid-logloss:0.1782\n",
      "[1200]\ttrain-logloss:0.177201\tvalid-logloss:0.17806\n",
      "[1250]\ttrain-logloss:0.176925\tvalid-logloss:0.177835\n",
      "[1300]\ttrain-logloss:0.176724\tvalid-logloss:0.17767\n",
      "[1350]\ttrain-logloss:0.176551\tvalid-logloss:0.177557\n",
      "[1400]\ttrain-logloss:0.176371\tvalid-logloss:0.177471\n",
      "[1450]\ttrain-logloss:0.176206\tvalid-logloss:0.177368\n",
      "[1500]\ttrain-logloss:0.176082\tvalid-logloss:0.177303\n",
      "[1550]\ttrain-logloss:0.175966\tvalid-logloss:0.177257\n",
      "[1600]\ttrain-logloss:0.175839\tvalid-logloss:0.177199\n",
      "[1650]\ttrain-logloss:0.175744\tvalid-logloss:0.177145\n",
      "[1700]\ttrain-logloss:0.175625\tvalid-logloss:0.177119\n",
      "[1750]\ttrain-logloss:0.175541\tvalid-logloss:0.17711\n",
      "[1800]\ttrain-logloss:0.17546\tvalid-logloss:0.177083\n",
      "[1850]\ttrain-logloss:0.175369\tvalid-logloss:0.177061\n",
      "[1900]\ttrain-logloss:0.175269\tvalid-logloss:0.177025\n",
      "[1950]\ttrain-logloss:0.175186\tvalid-logloss:0.176997\n",
      "[2000]\ttrain-logloss:0.17508\tvalid-logloss:0.176978\n",
      "[2050]\ttrain-logloss:0.174978\tvalid-logloss:0.176954\n",
      "[2100]\ttrain-logloss:0.174905\tvalid-logloss:0.176951\n",
      "[2150]\ttrain-logloss:0.174829\tvalid-logloss:0.176941\n",
      "[2200]\ttrain-logloss:0.174733\tvalid-logloss:0.176942\n",
      "[2250]\ttrain-logloss:0.174643\tvalid-logloss:0.176936\n",
      "[2300]\ttrain-logloss:0.174562\tvalid-logloss:0.17693\n",
      "[2350]\ttrain-logloss:0.174473\tvalid-logloss:0.176921\n",
      "[2400]\ttrain-logloss:0.174402\tvalid-logloss:0.176919\n",
      "[2450]\ttrain-logloss:0.174326\tvalid-logloss:0.176907\n",
      "[2500]\ttrain-logloss:0.174242\tvalid-logloss:0.176916\n",
      "Stopping. Best iteration:\n",
      "[2446]\ttrain-logloss:0.17433\tvalid-logloss:0.176906\n",
      "\n",
      "Full Out-Of-Fold score :  0.219896\n"
     ]
    }
   ],
   "source": [
    "train_renewal_preds_xg, test_renewal_preds_xg = fit_predict_xgboost(full_train_sparse, origin_train.renewal, dtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "origin_test['renewal_preds'] = (test_renewal_preds + test_renewal_preds_xg) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# submission['renewal'] = (test_renewal_preds + test_renewal_preds_xg) / 2\n",
    "# submission['incentives'] = 350\n",
    "# submission.to_csv('./output/10_mix_kfold7__350.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## incentives function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission['renewal'] = origin_test['renewal_preds']\n",
    "submission['incentives'] = np.sqrt(origin_test.premium)*2.8 * (np.exp2(1-origin_test.renewal_preds))\n",
    "\n",
    "submission.to_csv('./output/17_mix__sqrt2.8_exp2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
